{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import sys\n",
    "import prepare_adult_data\n",
    "import prepare_user_data\n",
    "import sampling_methods\n",
    "from misc import *\n",
    "\n",
    "\n",
    "csv_samples_header=['protected_class','sample_method','sample_size','sample_no','protected_frequency','log_geom_diversity']\n",
    "\n",
    "csv_table_header=['protected_class','sample_method','sample_size','no_of_samples','protected_freq_mean','entropy_mean','log_diversity_mean','Prob_>_50', 'protected_freq_std','entropy_std','log_diversity_std']\n",
    "\n",
    "kdpp = []\n",
    "pdpp = []\n",
    "pdpprop = []\n",
    "    \n",
    "def add_sample(path,S,record,reg_nrecords,labels):\n",
    "    l=[labels[i] for i in S]\n",
    "    fo=fraction_ones(l)\n",
    "    record.append(fo)\n",
    "    logd=log_diversity(np.array([reg_nrecords[i] for i in S]))\n",
    "    record.append(logd)\n",
    "    write_to_csv(path,record)\n",
    "    return (fo,logd)\n",
    "    \n",
    "    \n",
    "\n",
    "def run_tests(SAMPLE_SIZE,NO_SAMPLES,PATH_CSV,PATH_CSV_SUMMARY,reg_nrecords,protected_class,labels):\n",
    "    # run experiments and save results in two CSV files\n",
    "    # first with info about all samples\n",
    "    # second with cumulative statistics over all samples\n",
    "    DATA_SIZE=len(reg_nrecords)\n",
    "    \n",
    "    # clean up and prepare headers for the csv files with results\n",
    "    clean_file(PATH_CSV)\n",
    "    clean_file(PATH_CSV_SUMMARY)\n",
    "    write_to_csv(PATH_CSV,csv_samples_header)\n",
    "    write_to_csv(PATH_CSV_SUMMARY,csv_table_header)\n",
    "    \n",
    "    Y=np.array(reg_nrecords)\n",
    "    print(Y.shape)\n",
    "    M=range(0,DATA_SIZE)\n",
    "    \n",
    "    label0=filter(lambda i: labels[i]==0, M)\n",
    "    label1=filter(lambda i: labels[i]==1, M)\n",
    "    fraction_protected=fraction_ones(labels)\n",
    "    prop_sample_size=int(fraction_protected*SAMPLE_SIZE)\n",
    "    #different sampling methods to be run in this experiment\n",
    "    \n",
    "    #print(DATA_SIZE, label0.shape, label1.shape)\n",
    "   \n",
    "    sample_methods=['P-DPP', 'P-DPP-proportional'] #'everything','k-DPP', 'ki-DPP-proportional',\n",
    "        \n",
    "        \n",
    "    for method in sample_methods:\n",
    "    \n",
    "        #arrays for gathering statistics over samples\n",
    "        fos=[]\n",
    "        logds=[]\n",
    "        \n",
    "        print('method='+method)\n",
    "        for sample_no in range(NO_SAMPLES):\n",
    "            if method=='everything':\n",
    "                S=M\n",
    "            elif method=='uniform':\n",
    "                S=sampling_methods.uniform_sample(M,SAMPLE_SIZE)\n",
    "            elif method=='k-uniform':\n",
    "                S=sampling_methods.uniform_sample(label0,SAMPLE_SIZE/2)+sampling_methods.uniform_sample(label1,SAMPLE_SIZE/2)\n",
    "            elif method=='k-uniform-proportional':\n",
    "                S=sampling_methods.uniform_sample(label0,SAMPLE_SIZE-prop_sample_size)+sampling_methods.uniform_sample(label1,prop_sample_size)\n",
    "            elif method=='k-DPP':\n",
    "                S=sampling_methods.kDPPGreedySample(Y,SAMPLE_SIZE)\n",
    "                kdpp = S\n",
    "                print(kdpp.shape)\n",
    "            elif method=='k-DPP-MCMC':\n",
    "                S=sampling_methods.kDPPSampleMCMC(Y,SAMPLE_SIZE,DATA_SIZE*10)\n",
    "            elif method=='ki-DPP':\n",
    "                S=sampling_methods.kiDPPGreedySample(Y,[SAMPLE_SIZE/2,SAMPLE_SIZE/2],[labels[e] for e in M])\n",
    "            elif method=='ki-DPP-proportional':\n",
    "                S=sampling_methods.kiDPPGreedySample(Y,[SAMPLE_SIZE-prop_sample_size,prop_sample_size],[labels[e] for e in M])\n",
    "            elif method=='P-DPP':\n",
    "                S=sampling_methods.PartitionDPPGreedySample(Y,[SAMPLE_SIZE/2,SAMPLE_SIZE/2],[labels[e] for e in M])\n",
    "                pdpp = S\n",
    "            elif method=='P-DPP-MCMC':\n",
    "                S=sampling_methods.PartitionDPPSampleMCMC(Y,[SAMPLE_SIZE/2,SAMPLE_SIZE/2],[labels[e] for e in M],DATA_SIZE*10)\n",
    "            elif method=='P-DPP-proportional':\n",
    "                S=sampling_methods.PartitionDPPGreedySample(Y,[SAMPLE_SIZE-prop_sample_size,prop_sample_size],[labels[e] for e in M])\n",
    "                pdpprop = S\n",
    "            elif method=='old-P-DPP':\n",
    "                S=sampling_methods.OldPartitionDPPGreedySample(Y,[SAMPLE_SIZE/2,SAMPLE_SIZE/2],[labels[e] for e in M])\n",
    "            else:\n",
    "                print('error -- method not recognized')\n",
    "                sys.exit(0)\n",
    "            (fo,logd)=add_sample(PATH_CSV,S,[protected_class,method,len(S),sample_no],reg_nrecords,labels)\n",
    "            fos.append(fo)\n",
    "            logds.append(logd)\n",
    "            if method=='everything':\n",
    "                break\n",
    "                \n",
    "        # calculate summary of entropy over all samples          \n",
    "        entropies=np.array([H_entropy(p) for p in fos])\n",
    "        \n",
    "        # calculate summary of >50% statistic\n",
    "        frac_50=0.0\n",
    "        for p in fos:\n",
    "            if (abs(p-0.5)<0.001): frac_50+=0.5/len(fos)\n",
    "            elif p<0.5: frac_50+=0.0\n",
    "            else: frac_50+=1.0/len(fos)\n",
    "        \n",
    "        # write summary to a CSV file\n",
    "        write_to_csv(PATH_CSV_SUMMARY,\n",
    "            [protected_class,method,len(S),NO_SAMPLES,np.array(fos).mean(),\n",
    "            np.array(entropies).mean(),np.array(logds).mean(),frac_50,np.array(fos).std(),\n",
    "            np.array(entropies).std(),np.array(logds).std()])\n",
    "        \n",
    "        #S.to_csv(method+'.csv')\n",
    "    \n",
    "    \n",
    "\n",
    "      \n",
    "def run_user(prot_class):\n",
    "    # run the experiment on the Adult data set using prot_class as the protected attribute\n",
    "    \n",
    "    DATA_SIZE=5000\n",
    "    SAMPLE_SIZE=2500\n",
    "    NO_SAMPLES=2500\n",
    "    PATH_CSV='adult-samples'+prot_class+'.csv'\n",
    "    PATH_CSV_SUMMARY='adult-summary'+prot_class+'.csv'\n",
    "    \n",
    "    \n",
    "    # load the data set from file\n",
    "    # use https://github.com/mbilalzafar/fair-classification\n",
    "    nrecords,labels,classes=prepare_user_data.load_user_data(DATA_SIZE)\n",
    "    nrecords=nrecords.tolist()\n",
    "    nrecords=remove_zero_cols(nrecords)\n",
    "    normalize(nrecords)\n",
    "    gender=classes['gender']\n",
    "\n",
    "    \n",
    "    # prepare 0-1 arrays determining the gender and the race of the data points\n",
    "    gender=list(map(int,gender))\n",
    "    for i in range(len(gender)):\n",
    "        gender[i]=gender[i]%2\n",
    "        \n",
    "    # enrich the data vectors by adding pairwise product features  \n",
    "    reg_nrecords=np.array(nrecords).copy().tolist()\n",
    "    for e in range(len(nrecords)):\n",
    "        reg_nrecords[e]=add_features(nrecords[e])\n",
    "    reg_nrecords=remove_zero_cols(reg_nrecords)\n",
    "    X=np.asarray(nrecords)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # run experiments\n",
    "    if (prot_class=='gender-female'):\n",
    "        run_tests(SAMPLE_SIZE,NO_SAMPLES,PATH_CSV,PATH_CSV_SUMMARY,reg_nrecords,prot_class,gender)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file 'users.csv' in the current directory...\n",
      "File found in current directory..\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4ef14b39f359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gender-female'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ce851317b078>\u001b[0m in \u001b[0;36mrun_user\u001b[1;34m(prot_class)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;31m# load the data set from file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;31m# use https://github.com/mbilalzafar/fair-classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0mnrecords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepare_user_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0mnrecords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mnrecords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremove_zero_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\adobe\\fairDPP\\prepare_user_data.py\u001b[0m in \u001b[0;36mload_user_data\u001b[1;34m(load_data_size)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mattr_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_one_hot_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0minner_col\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattr_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\adobe\\fairDPP\\utils.py\u001b[0m in \u001b[0;36mget_one_hot_encoding\u001b[1;34m(in_arr)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mout_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_predicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "run_user('gender-female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file 'data_final.csv' in the current directory...\n",
      "File found in current directory..\n",
      "\n",
      "Loading only 5000 examples from the data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pvals < 0, pvals > 1 or pvals contains NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6c1c088b2726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg_nrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_methods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkDPPGreedySample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\adobe\\fairDPP\\sampling_methods.py\u001b[0m in \u001b[0;36mkDPPGreedySample\u001b[1;34m(Y, k)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mmultinom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultinom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmultinomSum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultinom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultinomSum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnprand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmultinom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multinomial\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pvals < 0, pvals > 1 or pvals contains NaNs"
     ]
    }
   ],
   "source": [
    "import sampling_methods\n",
    "\n",
    "DATA_SIZE=5000\n",
    "SAMPLE_SIZE=2500\n",
    "NO_SAMPLES=2500\n",
    "#PATH_CSV='adult-samples'+prot_class+'.csv'\n",
    "#PATH_CSV_SUMMARY='adult-summary'+prot_class+'.csv'\n",
    "\n",
    "\n",
    "# load the data set from file\n",
    "# use https://github.com/mbilalzafar/fair-classification\n",
    "df, nrecords,labels,classes=prepare_user_data.load_user_data(DATA_SIZE)\n",
    "nrecords=nrecords.tolist()\n",
    "nrecords=remove_zero_cols(nrecords)\n",
    "normalize(nrecords)\n",
    "gender=classes['gender']\n",
    "\n",
    "\n",
    "# prepare 0-1 arrays determining the gender and the race of the data points\n",
    "gender=list(map(int,gender))\n",
    "for i in range(len(gender)):\n",
    "    gender[i]=gender[i]%2\n",
    "\n",
    "# enrich the data vectors by adding pairwise product features  \n",
    "reg_nrecords=np.array(nrecords).copy().tolist()\n",
    "for e in range(len(nrecords)):\n",
    "    reg_nrecords[e]=add_features(nrecords[e])\n",
    "reg_nrecords=remove_zero_cols(reg_nrecords)\n",
    "X=np.asarray(nrecords)\n",
    "Y=np.array(reg_nrecords)\n",
    "\n",
    "S=sampling_methods.kDPPGreedySample(Y,2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
